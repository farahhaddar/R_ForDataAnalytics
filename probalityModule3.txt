when we speak data analysis we speak statistics and stats means building hypotisis based on 
calculations.

Probability means frequency or number of occurs or how likely thing to happen durning an event 
theoretical: logical thing frq/number of options exp: tail head proba will be for each 1/2(nb of options)
experimental: period/trial (n) exp: tossing coin fpr 12 times head appers 9 times and tail 3 proba will be h=9/12 and t= 3/12

Types of experiments:
1-Random: outcome is not predicted ahead before performing the experiments

SAMPLE SPACE: {H,T} is set of the possible  outcomes of an experiment
-> it can be uniform (chance/prob even between the sample elements ) or not-uniform ( chnace/prob is not equal alment A less/higher of alemnt B)
Event: subset of the sample space {} like odd even take only some elements tha fets the event from the big space 



Probability Rules:
-Probability 0<p<1
-p=0 the event is impossible 
-p=1 the event is certain 
-sum of all probabilities should be =1 
- Compound Probability (or / U ) 2 events happens together Mutually exclusive
--> P(A U B )= P(A)+P(B)- P(A n B ) common 
-Mutually exclusive events 2 events cannot accour together
-->P(A U B )= P(A)+P(B)
-Conditional Probability calculating P(B) given that P(A) Has already happen  (given that event x it will be in the denominator )
--> P(A/B)=P(AnB)/P(B)  P(B/A)= P(BnA)/P(A)
According to Base Theorem 
P(AnB)=P(BnA)
P(A/B)=P(BnA)*P(A)/P(B)
Note: Independent Events is when the occour of one event dosent effect the outcome of other event
P(B/A)= P(B) P(A/B)=P(A)  P(AnB)= P(A).P(B) or P(B).P(A)
P(A∪B) = P(A) + P(B) - P(A)P(B) 


Note when number of trials increase the more we get the equal proba and more to real sample 

Random Variable:
is mapping the samples space elements to a variable to test the frq of accourence to a real number line. 
s= {TTT,HHH,THH ...}
P(x=1)= Prob of having 1 Tail 1/12 
#random variable: number of heads (nummber of possible outcoms while doing the exp)

2 Types of a random variable:
--> Discrete: distinct value (1,2,3 )
--> Continuous: range 3.5  

Moments of a Random Variable: Calculations 
-mean(avg or expected value)

-variance = spread/dispersion (twzo3 w tashaot l values b3edan 3nl avg (mean))
Square of standard daviation 

-median= median is the number in the middle 
-mod= aktr value mawjod  high frq 

-skweness: measure of asummertry distrbution (enhyaz l data)
-->symatrical graph in the middle half  
mean median mode equal
-->positive lamma tail ykon t right (msh mnih ) mode median mean 
-->neg lamma ykoun tail to left (good) mean median mode 
note:Tail holds the extrem values 

-Kurtosis: describing the distribution of data 
-->Peak of line high(positive/leptokurtic)
-->middle(normal distrbution /mesokurtic) 
-->small lines high (negative/platykurti)


Probability Distributions:
is the distribution of p for all posible outcomes of random variables 
we guess it why ?
because if we have a clear idea how its changing we can prdict the future results 

Since we have 2 types of random variable each one has its own test:
- Discrete Probability:
 1- Bernoulli: discrete values yes/no t/f h/t nb of trying 1 
 2- Binomial: discrete values yes/no t/f h/t nb of trying 2 or more 
 n=nb of trial 
 p= prob of each success 
 mean=number*p 
 variance = n*p*(1-p)

 3- Possion:here could be any number of events occurring during a certain time interval so we calculate λ (lambda): Mean number of events during the interval.
  disrbution 0<d<infity 
  p(x)= (λ^x.e^-λ)/x!
  mean=variance= λ

- Continuous Probability
 1- normal: Gaussian distribuition
     mean is in the middle of the curve 
     bell-shaped cureved
 2- chi^2: 
    used when data comes from a population with a spesific distribuition
    degree of freedom df : Independent variable that are allowed to vary in a test or analysis 
    used for hyposthsis testing 
 3- student-t
 4- uniform : 
     data is distrbuted in a square form 
     prob density functions in a stable of accourence P with change of outcomes p(x)=(bound high-low )*1/b-a max,min and  a<x<b 
 anova z  hyposthsis testing 
 
 How to choose proper distribuition : 
 inference 
● Determine whether the data is continuous or
discrete.
● Consider the shape of the data and whether it
is symmetric, skewed, or has multiple modes.
● Look for any known properties or
characteristics of the data.
● Consider the application or problem at hand.
Examples:
Case study 1: Number of customers arriving at a bank during a specific
time period
● Poisson distribution
● Explanation:
○ The case study models the number of occurrences of a certain event in a
fixed interval of time or space.
○ In this case, we can model the number of customers arriving at a bank
during a specific time period
Case study 2: Daily Sales of a retail store
(Daily sales are likely to be distributed symmetrically around the central value)
● Normal distribution
● Explanation:
○ The distribution models continuous data that is symmetrically
distributed.
○ In this case, the daily sales of a retail store could be modeled with a
normal distribution, as sales are likely to be distributed symmetrically
around a central value (i.e., the mean).
Case study 3: Checking the relationship between a borrower’s credit score
and the likelihood of defaulting on a loan
● Chi2
 distribution
● Explanation:
○ The goal is to determine if there is a relationship
between the two variables (credit score and loan default)
○ This test calculates the chi-square statistic, which
measures how much the actual data deviates from what
we would expect if the two variables were independent.

Statistics:
1- Descriptive: drive summies and dispersion (mean/median/skweness..)
  -->  Central Tendency: 
  { mean(avg), rule mean
    mode(frequent/most showed element if 1 number repeted unimodal if 2 nb repeated bimodal if more than 2 multimodal )
    rule: remove na.rm and =="" and then mode <- function(x) {val <- unique(x)return(val[which.max(tabulate(match(x, val)))])}
    median (middle values if nb of all values is odd then the middle is the media if even we take avg of the 2 in the middle by n+n/2   ) rule median 
    note data should be sorted in assending oder
  }
  -->  Variablility: summary(df)
   {
     range: high value - low value in dataset rule=max-min  use min(df) max(df) to get values 
     variance (twzo3 data ) std^2 (substract each point in the dataset from the mean, then square all values , sum all the diffrences toghter , then divid the total over the nb of values in dataset) wider varince spread data 
     ruel:var(df)
     std ( the space from mean and data blocks on graph) its always positive or zero  std=rdical varance
     rule= sd(df)
  }
 

  2- Inferential (estnbat/thlel): used to predict and test hyposthsis
  main object is to connect the smaple statistic with the population params  
    --> Sampling distrbution: 
       population is the full dataset
       sample is a subset of the dataset and we have several subsets so for each dataset we calculate stats and then we end up with a sample set of the stats of these samples
       all subsets must  be same set
       when sample size increase the  sample error decrease and become near true 
       rule: use sample fn  
    --> Central Limit Theorem:
        sample  mean= population mean
        sd sample: sd/rdical n nb of samples
    --> Hyposthsis Testing:
      start with initial hypo/assumption and propose alternative reverse  hypo so we have 2 to be tested
      conduct test to either accept or reject the intial hypo accoding to the p value 
      H0=Null hypo ->test will give  P-value  which is that prob of h0=true 
      now we compare the pvalue if <=threshold reject if > thereshold accept 
      threshold is alfa=1-confidence level
      confidence level intervel: is how confindent i want the hyposthsis to be we take it from the problem case we are working with 
      {90%,50%,80%} 1-90%=0.01
      we pefom the t test result <- t.test(after, before, alternative = "greater") althernate means the mean of b is higher
     ttest ,ztest,anova (ANOVA compares the means of three or more groups to see if at least one mean is different from the others.)
     are the well known test for hyposthsis
      

Regression analysis:
--> statistical modeling used to visualize relationships and pattrens betwen dataset
predicting for future value x what y will be (look at previous data and prosceed )
 
 y=ax+b a is the linear relation that will take us from x to be its the slop  and b is the interception of x and y 


- 3 techniques of statistical modeling
1. linear Regression : goal is to estimate a nb 
   y (dependent var)=b0 (constant) +b1 (coefficient)*x1 (independent variable)
   the goal is to find the b0 and b1 
   -> we have the x and y  by supervised leraning algo
   -> any  x and y we want to find not in the dataset we can susbtete it in the eq and get the value

2. multi linear Regression
 same as liner but now we have  many vars 
 y=b0+b1.x1+b2.x2...
|/____ linking dots by ruler



3. logistic Regression: classificaion case (sunny/not accepted/not accepted )
 predicting a class/label of yes no maybe not a number for example

|__1/2____  1 before line label yes after line 2 no 

we take result from linear then put the values between 0/1 to be like male female so now we have a label  by sigmoied fn 


Model means relation betwen input x to autput y 
mapping  relating 


